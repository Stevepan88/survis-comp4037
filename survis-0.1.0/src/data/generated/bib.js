define({ entries : {
    "guyonneau2022": {
        "abstract": "This paper proposes a LiDAR-based navigation algorithm for agricultural robots, using an enhanced Ruby algorithm (RGOP) to extract crop rows from point clouds, coupled with a fuzzy controller. Tested in ROS/Gazebo across four crop configurations, RGOP achieves 100\\% success rate with 320 mm\u00b2 mean square error and 2.84 ms processing time, validated quantitatively. The method suits complex fields, and deep learning could optimize row detection.",
        "author": "Guyonneau, R\u00e9my and Mercier, Franck and Oliveira Freitas, Gabriel",
        "doi": "10.3390/s22228918",
        "journal": "Sensors",
        "keywords": "Traditional, Agricultural, LiDAR, Fuzzy Control",
        "number": "22",
        "pages": "8918",
        "title": "LiDAR-Only Crop Navigation for Symmetrical Robot",
        "type": "article",
        "url": "https://doi.org/10.3390/s22228918",
        "volume": "22",
        "year": "2022"
    },
    "iqbal2020": {
        "abstract": "The Phenotron robot integrates nodding 2D LiDAR and GPS for agricultural navigation and phenotyping, generating 3D point clouds for plant analysis. Gazebo simulations in cotton fields achieve 0.0778 m navigation error and 4\\% plant height error, validated quantitatively. RANSAC-based row fitting ensures robust navigation. Deep learning could enhance feature extraction.",
        "author": "Iqbal, J. and Xu, R. and Sun, S. and Li, C.",
        "doi": "10.3390/robotics9020046",
        "journal": "Robotics",
        "keywords": "Traditional, Agricultural, LiDAR+GPS, Quantitative",
        "number": "2",
        "pages": "46",
        "title": "Simulation of an Autonomous Mobile Robot for LiDAR-Based In-Field Phenotyping and Navigation",
        "type": "article",
        "url": "https://doi.org/10.3390/robotics9020046",
        "volume": "9",
        "year": "2020"
    },
    "lee2013": {
        "abstract": "This thesis develops a hierarchical control algorithm for MIT Cheetah\u2019s high-speed locomotion, using impedance control and gait modulation. MATLAB simulations validate 3.4 m/s trotting; experiments achieve 6 m/s with a cost of transport of 0.52, outperforming peers, validated quantitatively. ROS2 Gazebo replication confirms stability. RL could optimize parameters.",
        "author": "Lee, J.",
        "keywords": "Quadruped, Impedance Control, Quantitative",
        "school": "Massachusetts Institute of Technology",
        "title": "Hierarchical Controller for Highly Dynamic Locomotion Utilizing Pattern Modulation and Impedance Control: Implementation on the MIT Cheetah Robot",
        "type": "mastersthesis",
        "url": "https://dspace.mit.edu/handle/1721.1/85490",
        "year": "2013"
    },
    "sanchez2023": {
        "abstract": "This off-road UGV navigation method uses DRL and curriculum learning, converting 3D LiDAR point clouds into 2D traversability scans for an Actor-Critic neural network. Gazebo and real-world tests achieve 98\\% success, outperforming reactive navigation, validated quantitatively. Imitation learning could refine policies.",
        "author": "S\u00e1nchez, M. and Morales, J. and Mart\u00ednez, J. L.",
        "doi": "10.3390/s23063239",
        "journal": "Sensors",
        "keywords": "Machine Learning, Off-Road, RL, Quantitative",
        "number": "6",
        "pages": "3239",
        "title": "Reinforcement and Curriculum Learning for Off-Road Navigation of an UGV with a 3D LiDAR",
        "type": "article",
        "url": "https://doi.org/10.3390/s23063239",
        "volume": "23",
        "year": "2023"
    },
    "singh2024": {
        "abstract": "This study presents an enhanced RRT algorithm for indoor exploration, integrating LiDAR and Gmapping. A filtering module clusters boundary points, and a termination strategy improves efficiency. Gazebo and lab tests achieve 98.997\\% map completion in 85 seconds, validated quantitatively. RL could optimize RRT parameters.",
        "author": "Singh, A. V. and Agrawal, Y. and Gupta, R. and Bohara, V. A.",
        "booktitle": "2024 16th International Conference on COMmunication Systems & NETworkS (COMSNETS)",
        "doi": "10.1109/COMSNETS59351.2024.10427090",
        "keywords": "Traditional, Indoor, RRT, SLAM, Quantitative",
        "pages": "282--284",
        "title": "Filtering-RRT for Autonomous Indoor Navigation",
        "type": "inproceedings",
        "url": "https://doi.org/10.1109/COMSNETS59351.2024.10427090",
        "year": "2024"
    },
    "waga2025": {
        "abstract": "This deep hybrid model enables indoor navigation using a monocular RGB camera, combining CNN (VGG19, ResNet50) with random forest for commands. An augmented dataset of 67,680 frames yields 97.63\\% accuracy in simple settings, validated quantitatively. LiDAR-SLAM fusion could improve complex environments.",
        "author": "Waga, A. and Benhlima, S. and Bekri, A. and others",
        "doi": "10.1007/s11370-024-00569-8",
        "journal": "Intelligent Service Robotics",
        "keywords": "Machine Learning, Indoor, CNN, Quantitative",
        "pages": "75--95",
        "title": "A Novel Approach for End-to-End Navigation for Real Mobile Robots Using a Deep Hybrid Model",
        "type": "article",
        "url": "https://doi.org/10.1007/s11370-024-00569-8",
        "volume": "18",
        "year": "2025"
    },
    "xiao2022": {
        "abstract": "This survey reviews ML in robot navigation, classifying 74 studies into end-to-end, subsystem, and component learning. End-to-end methods dominate but lack generalization; hybrid approaches show promise. Literature analysis, supported by Gazebo simulations, validates ML\u2019s potential in dynamic environments.",
        "author": "Xiao, X. and Liu, B. and Warnell, G. and others",
        "doi": "10.1007/s10514-022-10039-8",
        "journal": "Autonomous Robots",
        "keywords": "Survey, Machine Learning, Literature Analysis",
        "pages": "569--597",
        "title": "Motion Planning and Control for Mobile Robot Navigation Using Machine Learning: A Survey",
        "type": "article",
        "url": "https://doi.org/10.1007/s10514-022-10039-8",
        "volume": "46",
        "year": "2022"
    },
    "zabar2024": {
        "abstract": "This navigation method combines DRL and SNN to optimize wall-following in 240x240 m occupancy grids. Simulations in 5663 maze environments reduce timesteps by 73-78\\% with 14-44 convergence trials, validated quantitatively. Aliasing elimination improves performance. Curriculum learning could enhance multi-task navigation.",
        "author": "Zabar, H. F. and Alaiwi, Y.",
        "doi": "10.1063/5.0199704",
        "journal": "AIP Conference Proceedings",
        "keywords": "Machine Learning, Maze, SNN, Quantitative",
        "number": "1",
        "title": "Application of Efficient Mobile Robot Navigation through Machine Learning Technique",
        "type": "article",
        "url": "https://doi.org/10.1063/5.0199704",
        "volume": "3092",
        "year": "2024"
    },
    "zhao2022": {
        "abstract": "This ROS-based navigation system for four-wheel robots uses Karto SLAM, A* planning, and DWA for obstacle avoidance. Gazebo and L-shaped corridor tests yield 0.019 m mapping accuracy, validated quantitatively. Wheel slip improves pose estimation. RL could optimize DWA parameters.",
        "author": "Zhao, J. and Liu, S. and Li, J.",
        "doi": "10.3390/s22114172",
        "journal": "Sensors",
        "keywords": "Traditional, Indoor, Karto SLAM, Quantitative",
        "number": "11",
        "pages": "4172",
        "title": "Research and Implementation of Autonomous Navigation for Mobile Robots Based on SLAM Algorithm under ROS",
        "type": "article",
        "url": "https://doi.org/10.3390/s22114172",
        "volume": "22",
        "year": "2022"
    },
    "zhao2023": {
        "abstract": "The Owlbot platform uses Gmapping SLAM with stepper motors for indoor navigation, fusing LiDAR and IMU data. Corridor experiments confirm mapping accuracy (<0.015 m error) with A* and DWA, validated quantitatively. Polynomial regression controls motors. Deep learning could enhance feature extraction.",
        "author": "Zhao, S. and Hwang, S. H.",
        "doi": "10.3390/s23073648",
        "journal": "Sensors",
        "keywords": "Traditional, Indoor, Gmapping, Quantitative",
        "number": "7",
        "pages": "3648",
        "title": "ROS-Based Autonomous Navigation Robot Platform with Stepping Motor",
        "type": "article",
        "url": "https://doi.org/10.3390/s23073648",
        "volume": "23",
        "year": "2023"
    }
}});